[
  {
    "objectID": "miniproject2.html",
    "href": "miniproject2.html",
    "title": "Mini-Project 2",
    "section": "",
    "text": "netflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(tidytuesdayR)\nlibrary(stringr)\n\n\nnetflix_titles2 &lt;- netflix_titles |&gt;\n  mutate(listed_in = str_replace_all(listed_in, \"[A-Z]\", tolower))\n\n\ngenre_titles &lt;- netflix_titles2 |&gt;\n  filter(str_detect(listed_in, \"comedy|comedies|drama|horror|documentary|action|crime|reality\")) |&gt;\n  mutate(genre = case_when(\n    str_detect(listed_in, \"comedy|comedies\") ~ \"Comedy\",\n    str_detect(listed_in, \"drama\") ~ \"Drama\",\n    str_detect(listed_in, \"horror\") ~ \"Horror\",\n    str_detect(listed_in, \"documentary\") ~ \"Documentary\",\n    str_detect(listed_in, \"action\") ~ \"Action\",\n    str_detect(listed_in, \"crime\") ~ \"Crime\",\n    str_detect(listed_in, \"reality\") ~ \"Reality\"\n  )) |&gt;\n  select(genre, type)\n\n\ngenre_plot &lt;-ggplot(genre_titles, aes(x = genre)) +\n    geom_bar() +\n    labs(\n      x = \"Genre\",\n      y = \"Count\",\n      title = \"# of Movies per Genre\"\n    )\nprint(genre_plot)\n\n\n\n\n\n\n\n\n\nyear_counts &lt;- netflix_titles |&gt;\n  group_by(release_year, type) |&gt;\n  summarise(count = n()) |&gt;\n  arrange(desc(count))\n\n\nyear_plot &lt;- \n  ggplot(year_counts, aes(x = release_year , y = count, color = type)) +\n  geom_point() +\n  labs(title = \"Number of Titles by Genre\", \n       x = \"Genre\", \n       y = \"Count\"\n       )\nprint(year_plot)\n\n\n\n\n\n\n\n\n\ndescription_length &lt;- netflix_titles |&gt;\n  mutate(description_length = str_length(description)) |&gt;\n  select(title, description, description_length) |&gt;\n  arrange(desc(description_length))\n\n\nmean_description_length &lt;- description_length |&gt;\n  summarize(mean_length = mean(description_length, na.rm = TRUE))\n\nmean_description_length\n\n# A tibble: 1 × 1\n  mean_length\n        &lt;dbl&gt;\n1        143.\n\n\n\nrating &lt;- netflix_titles |&gt;\n  filter(str_detect(rating, \"^(R|PG-13|PG|G)$\")) |&gt;\n  select(title, rating)\nrating\n\n# A tibble: 1,337 × 2\n   title       rating\n   &lt;chr&gt;       &lt;chr&gt; \n 1 23:59       R     \n 2 9           PG-13 \n 3 21          PG-13 \n 4 187         R     \n 5 3022        R     \n 6 22-Jul      R     \n 7 Æon Flux    PG-13 \n 8 10,000 B.C. PG-13 \n 9 13 Sins     R     \n10 14 Blades   R     \n# ℹ 1,327 more rows\n\n\nAnalysis on Tables/Plots:\nMy first table, I wanted to change the genre descriptions to all lowercase. I did this so that for my next table I could condense all of the genres into six different categories, allowing me to plot a graph showing the amount of movies/television shows in each genre.\nMy first graph represents that amount of movies/television shows in each genre. From this graph, we can see the most common genres are comedy and drama. The least common genres are crime and reality.\nFrom my second graph we can see the relationship between year, and movie/television show release date. We can infer from this graph that that a lot more movies and television shows were put on Netflix after the mid 2000s.\nI wanted to play around with the str_length function. So I took the length of all of the descriptions of each title. The mean of the description lengths was 143.1004 string characters.\nLastly, I created a new data frame that takes the title of the show and detects the R, PG-13, PG and G ratings\nReference:\nhttps://www.kaggle.com/datasets/shivamb/netflix-shows\nCredits to Shivam Bansal for this Dataset."
  },
  {
    "objectID": "food.html",
    "href": "food.html",
    "title": "Food Consumption",
    "section": "",
    "text": "food &lt;- read.csv(\"food_consumption.csv\")\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nggplot(food, aes(x = co2_emmission, y = consumption)) +\n  geom_point() +\n  labs(\n    x = \"CO2 Emissions\",\n    y = \"Consumption\",\n    title = \"Relationship food consumption and CO2 emissions\",\n  )\n\n\n\n\n\n\n\n\nHere is my data viz for food consumption! link to data set: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-05-26/all_drinks.csv"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello",
    "section": "",
    "text": "Welcome to my page!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Chloe Denhart",
    "section": "",
    "text": "About this site:\nWelcome to my website! I am a student at Pomona College majoring in Economics and minoring in Data Science. I am a member of the Pomona Woman’s Lacrosse team. Outside of Pomona, I am an avid camper and hiker!"
  },
  {
    "objectID": "drinks.html",
    "href": "drinks.html",
    "title": "All Drinks",
    "section": "",
    "text": "drinks &lt;- read.csv(\"all_drinks.csv\")\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nggplot(drinks, aes(x = strCategory)) +\n  geom_bar() +\n  labs(\n    x = \"Drink Category\",\n    y = \"Count\",\n    title = \"Analysis of amount of drinks in each drink category\",\n  ) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nHere is my data viz for food consumption!\nLink to data set: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-18/food_consumption.csv"
  },
  {
    "objectID": "miniproject3.html",
    "href": "miniproject3.html",
    "title": "Mini-Project 3",
    "section": "",
    "text": "The code here will provide an analysis on March Madness data. March madness is one of the most unpredictable tournaments in sports, as lower seeded teams are constantly “upsetting” higher seeded teams. The analysis done here will tackle the actual probability of lower seeded teams beating higher seeded teams. Our research question is: What is the probability of a lower-seeded team winning against a higher-seeded team in the first round of the 2023 NCAA March Madness tournament, and does this probability exceed 90%? To determine this I will conduct a permutation test with the hypothesis:\n\nNull hypothesis (H0) : the probability that a lower seeded team wins being less than or equal to 90% (Upset win rate ≤ 90%).\nAlternative hypothesis (Ha): the probability that a lower seeded team wins being greater than 90% (Upset win rate &gt; 90%)\nIn this case, we will be using a right tailed test permutation test. If the p-value is below the significance level (0.05), we will reject the null hypothesis, if it is not, we will fail to reject the null hypothesis.\n\nIn this case, we will be using a right tailed permutation test. If the p-value is below the significance level (0.05), we reject the null hypothesis, if it is not, we will fail to reject the null hypothesis.\n\nmarch_madness &lt;- read.csv(\"538 Ratings.csv\")\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(purrr)\n\n\nmarch_madness_2023 &lt;- march_madness |&gt;\n  filter(YEAR == 2023)\n\n\nmarch_madness_2023 &lt;- march_madness_2023 |&gt;\n  mutate(RESULT = ifelse(ROUND &lt; 64, \"win\", \"loss\"))\n\n\nteam_round &lt;- march_madness_2023 |&gt;\n  filter(SEED &gt;= 8) |&gt;\n  summarise(total_games = n())\n\n\ntotal_games &lt;- team_round |&gt; \n  pull(total_games)\n\n\nupset_rate &lt;- march_madness_2023 |&gt;\n  filter(SEED &gt;= 8 & RESULT == \"win\") |&gt;\n  summarise(upset_wins = n()) |&gt;\n  mutate(upset_rate = upset_wins / nrow(march_madness_2023)) |&gt;\n  pull(upset_rate)\n\n\nrandom_choice &lt;- function(num_teams) {\n  shuffled_seed &lt;- sample(c(\"lower\", \"higher\"), num_teams, replace = TRUE, prob = c(0.1, 0.9))\n  upset_ratio &lt;- mean(shuffled_seed == \"lower\")\n  return(upset_ratio)\n}\n\n\nset.seed(47)\nnum_exper &lt;- 5000\nnull_distribution &lt;- map_dbl(1:num_exper, ~ random_choice(total_games))\n\n\nggplot(data.frame(null_distribution), aes(x = null_distribution)) + \n  geom_histogram(bins = 30, color = \"black\", fill = \"skyblue\") +\n  labs(x = \"Proportion of teams that upset a higher seed\", \n       y = \"Count\",\n       title = \"Sampling distribution under the null hypothesis\")\n\n\n\n\n\n\n\n\n\n# p_value\np_value = sum(null_distribution &gt;= upset_rate) / num_exper\nprint(p_value)\n\n[1] 0.217\n\n\n\nggplot(data.frame(null_distribution), aes(x = null_distribution)) + \n  geom_histogram(bins = 30, color = \"black\", fill = \"skyblue\") +\n  geom_vline(xintercept = p_value, color = \"red\") + \n  labs(x = \"Proportion of teams that upset a higher seed\", \n       y = \"Count\",\n       title = \"Sampling distribution under the null hypothesis\")\n\n\n\n\n\n\n\n\nThis plot helps us visualize the null distribution of the data. The red line indicates the p_value is 0.217, and we know that our level of significance is 0.05. The p-value line does not line with the level of significance value in the right tail.\nThe p_value is 0.217, which means we reject the null hypothesis. Our p_value is greater than our level of significance, 0.05. This means that we fail to reject the null hypothesis. The analysis suggests that while lower-seeded teams do have upsets, the proportion of upsets is not as high as 90%. The probability of a lower-seeded team winning is likely not as extraordinary as 90%, according to your results.\nData Source:\nhttps://www.kaggle.com/datasets/nishaanamin/march-madness-data/data\nAuthor: NISHAAN AMIN\nThis data was sourced from data during the March Madness tournament. Specifically…\nThe data is pulled from:\n\nhttps://kenpom.com/\nhttps://www.barttorvik.com/#\nhttps://heatcheckcbb.com/\nhttps://abcnews.go.com/538\nhttps://www.espn.com/\nhttps://www.collegepollarchive.com/\nhttps://sports.yahoo.com/\n\nIt was updated about 8 months ago. The data is from 2008 - 2024 for the men’s teams. The year 2020 is not included because the tournament was canceled due to Covid. The first column of almost every dataset displays the year the data is from."
  }
]