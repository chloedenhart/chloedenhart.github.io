[
  {
    "objectID": "miniproject2.html",
    "href": "miniproject2.html",
    "title": "Mini-Project 2",
    "section": "",
    "text": "netflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(tidytuesdayR)\nlibrary(stringr)\n\n\nnetflix_titles2 &lt;- netflix_titles |&gt;\n  mutate(listed_in = str_replace_all(listed_in, \"[A-Z]\", tolower))\n\n\ngenre_titles &lt;- netflix_titles2 |&gt;\n  filter(str_detect(listed_in, \"comedy|comedies|drama|horror|documentary|action|crime|reality\")) |&gt;\n  mutate(genre = case_when(\n    str_detect(listed_in, \"comedy|comedies\") ~ \"Comedy\",\n    str_detect(listed_in, \"drama\") ~ \"Drama\",\n    str_detect(listed_in, \"horror\") ~ \"Horror\",\n    str_detect(listed_in, \"documentary\") ~ \"Documentary\",\n    str_detect(listed_in, \"action\") ~ \"Action\",\n    str_detect(listed_in, \"crime\") ~ \"Crime\",\n    str_detect(listed_in, \"reality\") ~ \"Reality\"\n  )) |&gt;\n  select(genre, type)\n\n\ngenre_plot &lt;-ggplot(genre_titles, aes(x = genre)) +\n    geom_bar() +\n    labs(\n      x = \"Genre\",\n      y = \"Count\",\n      title = \"# of Movies per Genre\"\n    )\nprint(genre_plot)\n\n\n\n\n\n\n\n\n\nyear_counts &lt;- netflix_titles |&gt;\n  group_by(release_year, type) |&gt;\n  summarise(count = n()) |&gt;\n  arrange(desc(count))\n\n\nyear_plot &lt;- \n  ggplot(year_counts, aes(x = release_year , y = count, color = type)) +\n  geom_point() +\n  labs(title = \"Number of Titles by Genre\", \n       x = \"Genre\", \n       y = \"Count\"\n       )\nprint(year_plot)\n\n\n\n\n\n\n\n\n\ndescription_length &lt;- netflix_titles |&gt;\n  mutate(description_length = str_length(description)) |&gt;\n  select(title, description, description_length) |&gt;\n  arrange(desc(description_length))\n\n\nmean_description_length &lt;- description_length |&gt;\n  summarize(mean_length = mean(description_length, na.rm = TRUE))\n\nmean_description_length\n\n# A tibble: 1 × 1\n  mean_length\n        &lt;dbl&gt;\n1        143.\n\n\n\nrating &lt;- netflix_titles |&gt;\n  filter(str_detect(rating, \"^(R|PG-13|PG|G)$\")) |&gt;\n  select(title, rating)\nrating\n\n# A tibble: 1,337 × 2\n   title       rating\n   &lt;chr&gt;       &lt;chr&gt; \n 1 23:59       R     \n 2 9           PG-13 \n 3 21          PG-13 \n 4 187         R     \n 5 3022        R     \n 6 22-Jul      R     \n 7 Æon Flux    PG-13 \n 8 10,000 B.C. PG-13 \n 9 13 Sins     R     \n10 14 Blades   R     \n# ℹ 1,327 more rows\n\n\nAnalysis on Tables/Plots:\nMy first table, I wanted to change the genre descriptions to all lowercase. I did this so that for my next table I could condense all of the genres into six different categories, allowing me to plot a graph showing the amount of movies/television shows in each genre.\nMy first graph represents that amount of movies/television shows in each genre. From this graph, we can see the most common genres are comedy and drama. The least common genres are crime and reality.\nFrom my second graph we can see the relationship between year, and movie/television show release date. We can infer from this graph that that a lot more movies and television shows were put on Netflix after the mid 2000s.\nI wanted to play around with the str_length function. So I took the length of all of the descriptions of each title. The mean of the description lengths was 143.1004 string characters.\nLastly, I created a new data frame that takes the title of the show and detects the R, PG-13, PG and G ratings\nReference:\nhttps://www.kaggle.com/datasets/shivamb/netflix-shows\nCredits to Shivam Bansal for this Dataset."
  },
  {
    "objectID": "food.html",
    "href": "food.html",
    "title": "Food Consumption",
    "section": "",
    "text": "food &lt;- read.csv(\"food_consumption.csv\")\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nggplot(food, aes(x = co2_emmission, y = consumption)) +\n  geom_point() +\n  labs(\n    x = \"CO2 Emissions\",\n    y = \"Consumption\",\n    title = \"Relationship food consumption and CO2 emissions\",\n  )\n\n\n\n\n\n\n\n\nHere is my data viz for food consumption! link to data set: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-05-26/all_drinks.csv"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello",
    "section": "",
    "text": "Welcome to my page!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Chloe Denhart",
    "section": "",
    "text": "About this site:\nWelcome to my website! I am a student at Pomona College majoring in Economics and minoring in Data Science. I am a member of the Pomona Woman’s Lacrosse team. Outside of Pomona, I am an avid camper and hiker!"
  },
  {
    "objectID": "drinks.html",
    "href": "drinks.html",
    "title": "All Drinks",
    "section": "",
    "text": "drinks &lt;- read.csv(\"all_drinks.csv\")\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nggplot(drinks, aes(x = strCategory)) +\n  geom_bar() +\n  labs(\n    x = \"Drink Category\",\n    y = \"Count\",\n    title = \"Analysis of amount of drinks in each drink category\",\n  ) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nHere is my data viz for food consumption!\nLink to data set: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-18/food_consumption.csv"
  },
  {
    "objectID": "miniproject3.html",
    "href": "miniproject3.html",
    "title": "Mini-Project 3",
    "section": "",
    "text": "The code here will provide an analysis on March Madness data. March madness is one of the most unpredictable tournaments in sports, as lower seeded teams are constantly “upsetting” higher seeded teams. The analysis done here will tackle the actual probability of lower seeded teams beating higher seeded teams. Our research question is: What is the probability of a lower-seeded team winning against a higher-seeded team in the first round of the 2023 NCAA March Madness tournament, and does this probability exceed 90%? To determine this I will conduct a permutation test with the hypothesis:\n\nNull hypothesis (H0) : the probability that a lower seeded team wins being less than or equal to 90% (Upset win rate ≤ 90%).\nAlternative hypothesis (Ha): the probability that a lower seeded team wins being greater than 90% (Upset win rate &gt; 90%)\n\nIn this case, we will be using a right tailed permutation test. If the p-value is below the significance level (0.05), we reject the null hypothesis, if it is not, we will fail to reject the null hypothesis.\n\nmarch_madness &lt;- read.csv(\"538 Ratings.csv\")\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(purrr)\n\n\nmarch_madness_2023 &lt;- march_madness |&gt;\n  filter(YEAR == 2023)\n\n\nmarch_madness_2023 &lt;- march_madness_2023 |&gt;\n  mutate(RESULT = ifelse(ROUND &lt; 64, \"win\", \"loss\"))\n\n\nteam_round &lt;- march_madness_2023 |&gt;\n  filter(SEED &gt;= 8) |&gt;\n  summarise(total_games = n())\n\n\ntotal_games &lt;- team_round |&gt; \n  pull(total_games)\n\n\nupset_rate &lt;- march_madness_2023 |&gt;\n  filter(SEED &gt;= 8 & RESULT == \"win\") |&gt;\n  summarise(upset_wins = n()) |&gt;\n  mutate(upset_rate = upset_wins / nrow(march_madness_2023)) |&gt;\n  pull(upset_rate)\n\n\nrandom_choice &lt;- function(num_teams) {\n  shuffled_seed &lt;- sample(c(\"lower\", \"higher\"), num_teams, replace = TRUE, prob = c(0.1, 0.9))\n  upset_ratio &lt;- mean(shuffled_seed == \"lower\")\n  return(upset_ratio)\n}\n\n\nset.seed(47)\nnum_exper &lt;- 5000\nnull_distribution &lt;- map_dbl(1:num_exper, ~ random_choice(total_games))\n\n\np_value &lt;- sum(null_distribution &gt;= upset_rate) / num_exper\n\n\nggplot(data.frame(null_distribution), aes(x = null_distribution)) + \n  geom_histogram(bins = 30, color = \"black\", fill = \"skyblue\") +\n  geom_vline(xintercept = p_value, color = \"red\") + \n  labs(x = \"Proportion of teams that upset a higher seed\", \n       y = \"Count\",\n       title = \"Sampling distribution under the null hypothesis\")\n\n\n\n\n\n\n\n\nThis plot helps us visualize the null distribution of the data. The red line indicates the p_value is 0.217, and we know that our level of significance is 0.05. The p-value line does not line with the level of significance value in the right tail.\nThe p_value is 0.217, which means we reject the null hypothesis. Our p_value is greater than our level of significance, 0.05. This means that we fail to reject the null hypothesis. The analysis suggests that while lower-seeded teams do have upsets, the proportion of upsets is not as high as 90%. The probability of a lower-seeded team winning is likely not as extraordinary as 90%, according to your results.\nData Source:\nhttps://www.kaggle.com/datasets/nishaanamin/march-madness-data/data\nAuthor: NISHAAN AMIN\nThis data was sourced from data during the March Madness tournament. Specifically…\nThe data is pulled from:\n\nhttps://kenpom.com/\nhttps://www.barttorvik.com/#\nhttps://heatcheckcbb.com/\nhttps://abcnews.go.com/538\nhttps://www.espn.com/\nhttps://www.collegepollarchive.com/\nhttps://sports.yahoo.com/\n\nIt was updated about 8 months ago. The data is from 2008 - 2024 for the men’s teams. The year 2020 is not included because the tournament was canceled due to Covid. The first column of almost every dataset displays the year the data is from."
  },
  {
    "objectID": "miniproject4.html",
    "href": "miniproject4.html",
    "title": "Mini-Project 4",
    "section": "",
    "text": "In this project, I will reproduce the graph created in Figure 1 of the Voss (2020) study using data from the Wideband Acoustic Immittance (WAI) Database. The graph will plot frequency against mean absorption for the 12 studies referenced in Figure 1, showing the differences across studies. I will also explore a second study, Aithal (2013), focusing on differences in mean absorption by sex. Both analyses will involve querying the WAI Database with SQL to extract the necessary data and using R to create plots.\n\nlibrary(RMariaDB)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n\nlibrary(RMariaDB)\nlibrary(tidyverse)\n\nlibrary(RMariaDB)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\n\n\n\nSHOW TABLES;\n\n\n7 records\n\n\nTables_in_wai\n\n\n\n\nCodebook\n\n\nMeasurements\n\n\nMeasurements_pre2020\n\n\nPI_Info\n\n\nPI_Info_OLD\n\n\nSubjects\n\n\nSubjects_pre2020\n\n\n\n\n\n\nDESCRIBE Measurements;\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nSubjectNumber\nint\nNO\nPRI\nNA\n\n\n\nSession\nint\nNO\nPRI\nNA\n\n\n\nEar\nvarchar(50)\nNO\nPRI\n\n\n\n\nInstrument\nvarchar(50)\nNO\nPRI\n\n\n\n\nAge\nfloat\nYES\n\nNA\n\n\n\nAgeCategory\nvarchar(50)\nYES\n\nNA\n\n\n\nEarStatus\nvarchar(50)\nYES\n\nNA\n\n\n\nTPP\nfloat\nYES\n\nNA\n\n\n\nAreaCanal\nfloat\nYES\n\nNA\n\n\n\n\n\n\n\nSELECT *\nFROM Measurements\nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSession\nEar\nInstrument\nAge\nAgeCategory\nEarStatus\nTPP\nAreaCanal\nPressureCanal\nSweepDirection\nFrequency\nAbsorbance\nZmag\nZang\n\n\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n210.938\n0.0333379\n113780000\n-0.233504\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n234.375\n0.0315705\n103585000\n-0.235778\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n257.812\n0.0405751\n92951696\n-0.233482\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n281.250\n0.0438399\n86058000\n-0.233421\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n304.688\n0.0486400\n79492800\n-0.232931\n\n\n\n\n\n\nSELECT DISTINCT Identifier\nFROM Measurements;\n\n\nDisplaying records 1 - 10\n\n\nIdentifier\n\n\n\n\nAbur_2014\n\n\nAithal_2013\n\n\nAithal_2014\n\n\nAithal_2014b\n\n\nAithal_2015\n\n\nAithal_2017a\n\n\nAithal_2017b\n\n\nAithal_2019a\n\n\nAithal_2019b\n\n\nAithal_2020a\n\n\n\n\n\n\nSELECT \n  m.Identifier,\n  CONCAT(pi.AuthorsShortList,pi.Year,m.Instrument, m.Frequency) AS Label,\n  m.Frequency,\n  AVG(m.Absorbance) AS Mean_Absorbance,\n  COUNT(DISTINCT m.SubjectNumber, m.Ear) AS Unique_Ears\nFROM Measurements AS m\nJOIN PI_Info AS pi\n  ON m.Identifier = pi.Identifier\nWHERE m.Identifier IN ('Abur_2014', 'Werner_2010', 'Voss_2020', 'Feeny_2017', 'Groon_2015', 'Lewis_2015', 'Liu_2008', 'Rosowski_2012', 'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', 'Voss_1994', 'Voss_2010')\nGROUP BY m.Identifier, m.Frequency, pi.AuthorsShortList, pi.Year, m.Instrument\nORDER BY pi.Year, m.Frequency;\n\n\nears |&gt; \n  ggplot(aes(x = Frequency, y = Mean_Absorbance, color = Identifier)) +\n  geom_line() +\n  labs(\n    title = \"Mean Absorbance From Each Publication in WAI Database\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n    color = \"Study\"\n  ) +\n  scale_x_continuous(limits = c(200, 8000)) +\n  scale_y_continuous(limits = c(0, 1)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis graphs analyzes 12 different studies from the WAI database. Each line represents data from a specific study, identified by the author, year, instrument, and the number of unique ears measured. The x-axis shows frequency in Hertz (Hz), ranging from 200 Hz to 8000 Hz, while the y-axis displays mean absorption values ranging from 0 to 1. This plot highlights variations in mean absorption across different studies and instruments, demonstrating how measurement techniques and populations may influence auditory outcomes. Each study has differing ranges in mean absorbency and frequency.\nNow we will reproduce a similar graph, finding a study in the same database where subjects of different sex. In doing this I will be using the Aithal (2013) study.\n\nSELECT \n  m.Identifier,\n  m.Frequency,\n  s.Sex,\n  AVG(m.Absorbance) AS Mean_Absorbance,\n  COUNT(DISTINCT m.SubjectNumber, m.Ear) AS Unique_Ears\nFROM Measurements AS m\nJOIN Subjects AS s\n  ON m.SubjectNumber = s.SubjectNumber\nWHERE m.Identifier = 'Aithal_2013'\nGROUP BY m.Frequency, s.Sex\nORDER BY m.Frequency, s.Sex;\n\n\nSELECT Sex, Identifier\nFROM Subjects\n\n\nsex_analysis |&gt;\n  ggplot(aes(x = Frequency, y = Mean_Absorbance, color = Sex)) +\n  geom_line() +\n  labs(\n    title = \"Frequency vs. Mean Absorbance by Sex for Aithal_2013\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n    color = \"Sex\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(limits = c(200, 8000)) +\n  scale_y_continuous(limits = c(0, 1)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis graphs analyzes just the Aithal (2013) study from the WAI database. Each line represents data from a specific sex group. There seems to be some mistake in the data where “Female” was spelled “Femake”. The x-axis shows frequency in Hertz (Hz), ranging from 200 Hz to 8000 Hz, while the y-axis displays mean absorption values ranging from 0 to 1. This plot highlights that there are not distince variations in mean absorption and frequency across different sex’s, demonstrating that sex does not influence auditory outcomes."
  }
]